{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["jAr1Yz-KQOIw","flgeE8r_QRcC","EhGL_XO6QVjc","75lZi4Gz7suH"],"mount_file_id":"1IOLwkUTVdjqAK7H9TnmbcNop0Uowvv1l","authorship_tag":"ABX9TyOlAT9kf4ssjCot8VszP7bP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# torchvision.models.alexnet, vgg, resnet 해보기"],"metadata":{"id":"7k9YiGq4tcHH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 이미지 분류를 위한 신경망 6.1 (LeNet-5,  AlexNet, VGGNet, GoogLeNet, ResNet)"],"metadata":{"id":"C5OaSTdUo1Up"}},{"cell_type":"markdown","source":["## 1. LeNet-5"],"metadata":{"id":"jAr1Yz-KQOIw"}},{"cell_type":"markdown","source":["1. **LeNet-5**\n","- 모델의 기본 조건: 32*32 img size / 손글씨\n","- ✅ 모델 구조\n","  <img src = \"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zxrGm9YBq__CPE3EUZKDOQ.jpeg\" width = 500 height = 250>\n","  <img src = \"https://thebook.io/img/080263/202.jpg\" width = 400 height = 200>\n","\n","- ✅ advanced 모델 구조\n","  - tanh -> relu\n","  - average pooling -> max pooling\n","  - softmax 는 제외\n","  - fc 전에 파라미터 너무 많아지므로 adaptive avg pooling 추가\n","  - 두 fc 는 다음과 같이 변경\n","\n","    - [C1] conv1: 5*5 (`kernel_size` = 5), `out_channels` = 6\n","    - [S1] sub-sampling(= down sampling)\n","      - 공간 해상도 (H*W) 줄이기\n","      - maxpool2d: 28 -> 14 가 되어야 하니까 `kernel_size` = 2, `stride` = 2\n","  $$ out = \\lfloor \\frac{in + 2p - k}{s} \\rfloor + 1 $$\n","    - [C2] conv2: 5*5 (`kernel_size` = 5), `out_channels` = 16\n","    - [S2] maxpool2d: (`kernel_size` = 2, `stride` = 2)\n","    - [C3] conv3: 5*5 (`kenel_size` = 5), `out_channels` = 120\n","    - [A1] AdaptiveAvgPool2d: `kernel_size` = 5\n","    - [F1] fc1: `Linear(120*5*5 , 120)` # img size 에 맞게\n","    - [F2] fc2: `Linear(120, 84)`\n","    - [F3] fc3: `Linear(84, 2)`\n","  \n","- => dog-cat 문제는 이미지 크기 256 로 해서 변경\n","- ☑️ Result\n","  - 데이터 수 부족해서 성능 안 좋은 것임 (한 클래스만 찍힘)\n","\n"],"metadata":{"id":"JUkByF9grO5Y"}},{"cell_type":"code","source":[],"metadata":{"id":"Fer13IEdsr5P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. cuda device\n","2. data path, transforms.Compose([transforms.]), ImageFolder\n","- train, test 나누기 (os.listdir, train_test_split)\n","- train, test 폴더 생성 및 아래 각 클래스 폴더 생성 (label 이름 인식을 위해서)\n","- 기존 이미지들 이동하기\n","- test 의 경우 transform 랜덤 변환 X\n","3. batch size 변수, dataloader\n","4. 이미지 시각화\n","\t- subplot, imshow, title, axis off, tight_layout, show\n","5. 모델: LeNet-5\n","\t- 모델 정의 (torchvision.models, timm 모두 없으므로 직접 ✅class 로 모델 만들기✅)\n","\t- 모델 device 에 올리기 및 출력해보기\n","\t- 파라미터 확인하기\n","6. lr, criterion, optimizer 정의\n","7. epochs 수 정하기\n","- epoch for 문\n","\t- train 순서\n","\t\t- model train 모드로\n","\t\t- loss, total, correct = 0\n","\t\t- loader for문\n","\t\t\t- img, label device 에 올리기\n","\t\t\t- model 에 넣기\n","\t\t\t- loss\n","\t\t\t- optimizer zero grad, 기울기 계산, 역전파 수행 (train 에서만)\n","\t\t\t- 현재의 배치 구하고 loss 누적\n","\t\t\t- pred 구하고 correct 구하기\n","\t\t\t- total 구하기\n","\t\t- avg loss, acc 계산\n","\t\t- plot 그리기 위해 list 에 저장\n","\t- test 순서\n","\t\t- model eval 모드로\n","\t\t- loss, total, correct = 0\n","\t\t- no grad()\n","\t\t\t- loader for 문\n","\t\t\t\t- 동일\n","\t\t- avg loss, acc 계산\n","\t\t- plot 그리기 위해 list 에 저장\n","\t- loss, acc 출력\n","\t- 모델 갱신되면 저장\n","8. train, test acc, loss plot\n","9. 실제, 예측 결과, 이미지 시각화 (마지막 배치에서 일부만) -> 오분류 이미지 확인\n","10. (feature map 시각화)\n"],"metadata":{"id":"EyxkELUkr70S"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"753fkJcYowI2"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"Ba7GGQV4snTP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path_cat = \"/content/drive/MyDrive/딥러닝 파이토치 교과서/6.1_Image Classification/data/dogs-vs-cats/Cat\"\n","data_path_dog = \"/content/drive/MyDrive/딥러닝 파이토치 교과서/6.1_Image Classification/data/dogs-vs-cats/Dog\"\n","\n","import os\n","cat_list = os.listdir(data_path_cat)\n","dog_list = os.listdir(data_path_dog)\n","\n","from sklearn.model_selection import train_test_split\n","train_cat, test_cat = train_test_split(cat_list)\n","train_dog, test_dog = train_test_split(dog_list)\n","\n","\n","\n","base_path = \"/content/drive/MyDrive/딥러닝 파이토치 교과서/6.1_Image Classification/data/\"\n","\n","train_cat_dir = os.path.join(base_path, 'train', 'cat')\n","train_dog_dir = os.path.join(base_path, 'train', 'dog')\n","\n","test_cat_dir = os.path.join(base_path, 'test', 'cat')\n","test_dog_dir = os.path.join(base_path, 'test', 'dog')\n","\n","\n","\n","for d in [train_cat_dir, train_dog_dir, test_cat_dir, test_dog_dir]:\n","  os.makedirs(d, exist_ok = True)\n","\n","import shutil\n","\n","def path(file_list, path1, path2):\n","  for f in file_list:\n","    shutil.copy(os.path.join(path1, f), os.path.join(path2, f))\n","\n","path(train_cat, data_path_cat, train_cat_dir)\n","path(train_dog, data_path_dog, train_dog_dir)\n","path(test_cat, data_path_cat, test_cat_dir)\n","path(test_dog, data_path_dog, test_dog_dir)\n","\n","train_data_path = os.path.join(base_path, 'train')\n","test_data_path = os.path.join(base_path, 'test')"],"metadata":{"id":"geqM79Lao4lD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import transforms\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize([256, 256]),\n","    #transforms.RandomResizedCrop(224), # 이걸 사용하려면 모델 넣을 때, 224 로 (test 도 resize 시 224 로)\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor()\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize([256, 256]),\n","    transforms.ToTensor()\n","])\n","\n","\n","from torchvision.datasets import ImageFolder\n","train_dataset = ImageFolder(train_data_path, transform = train_transform)\n","test_dataset = ImageFolder(test_data_path, transform = test_transform)"],"metadata":{"id":"CJN2GscODs9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","\n","from torch.utils.data import DataLoader\n","train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"],"metadata":{"id":"BP0Tca4RLmYb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]"],"metadata":{"id":"XFS7LJyqMg7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader.dataset.class_to_idx"],"metadata":{"id":"Fi0uSZ0NM6J8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import random\n","\n","plt.figure(figsize = (10, 10))\n","\n","for idx in range(16):\n","  i = random.randint(0, len(train_dataset))\n","  data = train_dataset[i]\n","  plt.subplot(4, 4, idx+1)\n","  plt.imshow(data[0].permute(1, 2, 0))\n","  if data[1] == 0:\n","    t = 'cat'\n","  else:\n","    t = 'dog'\n","\n","  plt.title(t)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"-YIKDKdGMFA_","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn"],"metadata":{"id":"Q7K3wPiwJX73"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LeNet5(nn.Module):\n","  def __init__(self):\n","    super(LeNet5, self).__init__()\n","    self.relu = nn.ReLU()\n","\n","    # transform 에서 resize 로 256\n","    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 5) # (256+2*0-5) / 1 + 1 = 252\n","    self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2) # (252+2*0-2) / 2 + 1 = 126\n","    self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 5) # (126+2*0-5) / 1 + 1 = 122\n","    self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2) # (122+2*0-2) / 2 + 1 = 61\n","    self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = 5) # (61+2*0-5) / 1 + 1 = 57\n","    self.avg  = nn.AdaptiveAvgPool2d((5,5))\n","    self.fc1 = nn.Linear(120*5*5, 120)\n","    self.fc2 = nn.Linear(120, 84)\n","    self.fc3 = nn.Linear(84, 2)\n","\n","  def forward(self, x):\n","    out = self.conv1(x)\n","    out = self.relu(out)\n","    out = self.pool1(out)\n","\n","    out = self.conv2(out)\n","    out = self.relu(out)\n","    out = self.pool2(out)\n","\n","    out = self.conv3(out)\n","    out = self.relu(out) # (120, 57, 57)\n","    out = self.avg(out) # (120, 5, 5)\n","\n","    out = self.fc1(out.view(-1, 120*5*5))\n","    out = self.relu(out)\n","    out = self.fc2(out)\n","    out = self.relu(out)\n","    out = self.fc3(out)\n","\n","    return out\n"],"metadata":{"id":"bHNHMYWKJXzR","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ao4R8so8cBjo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = LeNet5()\n","model.to(device)\n","print(model)"],"metadata":{"id":"qI_M3O-dhOtv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","  print(name, param.data)"],"metadata":{"collapsed":true,"id":"nl5XwlpDOEQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn import CrossEntropyLoss\n","from torch.optim import Adam\n","\n","learning_rate = 0.05\n","criterion = CrossEntropyLoss()\n","optimizer = Adam(params = model.parameters(), lr = learning_rate)"],"metadata":{"id":"4Gfv7z1nP_3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","train_loss_list = []\n","train_acc_list = []\n","test_loss_list = []\n","test_acc_list = []\n","test_acc = 0\n","\n","\n","for epoch in range(epochs):\n","  model.train()\n","  train_loss = 0\n","  train_total = 0\n","  train_correct = 0\n","\n","  for img, label in train_loader:\n","    img, label = img.to(device), label.to(device)\n","    out = model(img)\n","    loss = criterion(out, label.long())\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    bs = img.size(0)\n","\n","    train_loss += loss.item() * bs\n","\n","    pred = out.argmax(dim = 1)\n","    train_correct += (pred == label).sum().item()\n","\n","    train_total += bs\n","\n","  avg_train_loss = train_loss / train_total\n","  avg_train_acc = train_correct / train_total * 100\n","  train_loss_list.append(avg_train_loss)\n","  train_acc_list.append(avg_train_acc)\n","\n","  model.eval()\n","  test_loss, test_total, test_correct = 0, 0, 0\n","  with torch.no_grad():\n","    for img, label in test_loader:\n","      img, label = img.to(device), label.to(device)\n","      out = model(img)\n","      loss = criterion(out, label.long())\n","\n","      bs = img.size(0)\n","\n","      test_loss += loss.item() * bs\n","\n","      pred = out.argmax(dim = 1)\n","      test_correct += (pred == label).sum().item()\n","\n","      test_total += bs\n","\n","  avg_test_loss = test_loss / test_total\n","  avg_test_acc = test_correct / test_total * 100\n","  test_loss_list.append(avg_test_loss)\n","  test_acc_list.append(avg_test_acc)\n","\n","  print(\n","          f\"[{epoch+1}/{epochs}] \"\n","          f\"train_loss: {avg_train_loss:.4f}, train_acc: {avg_train_acc:.2f}% | \"\n","          f\"test_loss: {avg_test_loss:.4f}, test_acc: {avg_test_acc:.2f}%\"\n","      )\n","\n","  if avg_test_acc > test_acc:\n","    test_acc = avg_test_acc\n","    torch.save(model, 'model.pth')"],"metadata":{"id":"8psPie_zUWDZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NUr2aamRYaIl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["out.size(), label.size()"],"metadata":{"id":"yen00gkEWEx8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.subplot(2, 2, 1)\n","plt.plot(train_acc_list)\n","plt.title('train acc')\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(test_acc_list)\n","plt.title('test acc')\n","\n","plt.subplot(2, 2, 3)\n","plt.plot(train_loss_list)\n","plt.title('train loss')\n","\n","plt.subplot(2, 2, 4)\n","plt.plot(test_loss_list)\n","plt.title('test loss')\n","\n","plt.show()"],"metadata":{"id":"5BD9SPdK456X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img.size(0)"],"metadata":{"id":"UEI1KdFIW_Ua"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 마지막 배치의 img, pred 와 label 비교\n","# test 의 경우 shuffle = False 이므로 순서대로 나오므로 마지막 배치는 dog 만 있음\n","\n","plt.figure(figsize = (10, 10))\n","\n","for i in range(20):\n","  plt.subplot(4, 5, i+1)\n","\n","  plt.imshow(img[i].permute(1, 2, 0).cpu())\n","  if pred[i].cpu().item() == 0:\n","    t_pred = 'cat'\n","  else:\n","    t_pred = 'dog'\n","\n","  if label[i].cpu().item() == 0:\n","    t_real = 'cat'\n","  else:\n","    t_real = 'dog'\n","\n","  plt.title(t_pred + \"(real: \" + t_real + \")\")\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"hdaxFij-5kTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"U1G4b0BtKKjF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. AlexNet"],"metadata":{"id":"flgeE8r_QRcC"}},{"cell_type":"markdown","source":["2. **AlexNet**\n","- torchvision.models.alexnet 이 이미 있지만 구현해봄\n","- ✅ 모델 구조\n","  <img src = \"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K7GvxwsWRbC_Ms2YsGsAMg.jpeg\" width = 450 height = 250>\n","  <img src = \"https://resources-public-blog.modulabs.co.kr/blog/prd/content/259481/Untitled-4.png\" width = 400 height = 200>\n","\n","- ✅ advanced 구조\n","  - dog-cat 문제 위해 f4, f5 추가 및 softmax 층 제거\n","  - dropout 층은 동일하게 f1, f2 에만 추가\n","    - [C1] conv1: 11*11 (`kernel_size` = 11), `stride` = 4, `out_channels` = 96\n","    - [S1] sub-sampling(= down sampling)\n","      - 공간 해상도 (H*W) 줄이기\n","      - maxpool2d: `kernel_size` = 3, `stride` = 2\n","  $$ out = \\lfloor \\frac{in + 2p - k}{s} \\rfloor + 1 $$\n","    - [C2] conv2: 5*5 (`kernel_size` = 5), `pad` = 2, `out_channels` = 256\n","    - [S2] maxpool2d: (`kernel_size` = 3), `stride` = 2\n","    - [C3] conv3: 3*3 (`kenel_size` = 3), `pad` = 1, `stride` = 1, `out_channels` = 384\n","    - [C4] conv4: 3*3 (`kernel_size` = 3), `pad` = 1, `stride` = 1, `out_channels` = 384\n","    - [C5] conv5: 3*3 (`kernel_size` = 3), `pad` = 1, `stride` = 1, `out_channels` = 256\n","    - [S3] maxpool2d: 3*3 (`kernel_size` = 3), `stride` = 2\n","    - [F1] fc1: `Linear(9216, 4096)` # 9216 인 이유는 227 size 이면 256* 6 * 6\n","    - [D1] dropout: `Dropout(0.5)`\n","    - [F2] fc2: `Linear(4096, 4096)`\n","    - [D2] dropout: `Dropout(0.5)`\n","    - [F3] fc3: `Linear(4096, 1000)`\n","    - [F4] fc4: `Linear(1000, 256)`\n","    - [F5] fc5: `Linear(256, 2)`\n","\n","- ☑️ Result\n","  - 데이터 수 부족해서 성능 안 좋은 것임 (한 클래스만 찍힘)"],"metadata":{"id":"E5HkgPvpKJIp"}},{"cell_type":"code","source":[],"metadata":{"id":"xwR6OwCmKJIq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. cuda device\n","2. data path, transforms.Compose([transforms.]), ImageFolder\n","- train, test 나누기 (os.listdir, train_test_split)\n","- train, test 폴더 생성 및 아래 각 클래스 폴더 생성 (label 이름 인식을 위해서)\n","- 기존 이미지들 이동하기\n","- test 의 경우 transform 랜덤 변환 X\n","- ✅ AlexNet 의 경우 정규화 필수 (ImageTransform)\n","\t- `transforms.Normalize(mean = [], std = [])`\n","\t- `ToTensor()` 뒤에 적용\n","\t- **mean, std 구하기: 반드시 train 셋만 가지고 구해야함**\n","\t\t- path 이용해서\n","\t\t- imagenet 관행\n","\t\t\t- mean = [0.485, 0.456, 0.406]\n","\t\t\t- std = [0.229, 0.224, 0.225]\n","3. batch size 변수, dataloader\n","4. 이미지 시각화\n","\t- subplot, imshow, title, axis off, tight_layout, show\n","\t- Normalize 했을 경우 역정규화해서 imshow\n","5. 모델: AlexNet\n","\t- 모델 정의 (torchvision.models 에 있지만 ✅class 로 모델 만들기✅)\n","\t- 모델 device 에 올리기 및 출력해보기\n","\t- 파라미터 확인하기\n","6. lr, criterion, optimizer 정의\n","7. epochs 수 정하기\n","- epoch for 문\n","\t- train 순서\n","\t\t- model train 모드로\n","\t\t- loss, total, correct = 0\n","\t\t- loader for문\n","\t\t\t- img, label device 에 올리기\n","\t\t\t- model 에 넣기\n","\t\t\t- loss\n","\t\t\t- optimizer zero grad, 기울기 계산, 역전파 수행 (train 에서만)\n","\t\t\t- 현재의 배치 구하고 loss 누적\n","\t\t\t- pred 구하고 correct 구하기\n","\t\t\t- total 구하기\n","\t\t- avg loss, acc 계산\n","\t\t- plot 그리기 위해 list 에 저장\n","\t- test 순서\n","\t\t- model eval 모드로\n","\t\t- loss, total, correct = 0\n","\t\t- no grad()\n","\t\t\t- loader for 문\n","\t\t\t\t- 동일\n","\t\t- avg loss, acc 계산\n","\t\t- plot 그리기 위해 list 에 저장\n","\t- loss, acc 출력\n","\t- 모델 갱신되면 저장\n","8. train, test acc, loss plot\n","9. 실제, 예측 결과, 이미지 시각화 (마지막 배치에서 일부만) -> 오분류 이미지 확인\n","10. (feature map 시각화)\n","\n"],"metadata":{"id":"JAq0tCe2KJIq"}},{"cell_type":"code","source":[],"metadata":{"id":"T27cHDp1rBik"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-TVsyi0siFV"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"QfM5zTTerBX7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_path = '/content/drive/MyDrive/딥러닝 파이토치 교과서/6.1_Image Classification/data/train/**/*.*'\n","\n","import os, numpy as np\n","from PIL import Image\n","from glob import glob\n","\n","paths = glob(train_data_path, recursive=True)\n","sum_c = np.zeros(3, dtype=np.float64)\n","sq_c  = np.zeros(3, dtype=np.float64)\n","count = 0\n","\n","for p in paths:\n","    img = Image.open(p).convert(\"RGB\")\n","    img = img.resize((224, 224))                # 모델 입력 크기에 맞춤(권장)\n","    arr = np.asarray(img, dtype=np.float32) / 255.0  # [H,W,3] in [0,1]\n","    sum_c += arr.reshape(-1, 3).sum(axis=0)\n","    sq_c  += (arr.reshape(-1, 3)**2).sum(axis=0)\n","    count += arr.shape[0] * arr.shape[1]\n","\n","mean = (sum_c / count).tolist()\n","std  = np.sqrt(sq_c / count - np.array(mean)**2).tolist()\n","print(\"mean =\", mean, \"\\nstd =\", std)"],"metadata":{"id":"6YJJv6y6j4PO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_path = '/content/drive/MyDrive/딥러닝 파이토치 교과서/6.1_Image Classification/data/train'\n","test_data_path = '/content/drive/MyDrive/딥러닝 파이토치 교과서/6.1_Image Classification/data/test'\n","\n","from torchvision import transforms\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize([227, 227]),\n","    #transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean = mean, std = std)\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize([227, 227]),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean = mean, std = std)\n","])\n","\n","\n","from torchvision.datasets import ImageFolder\n","\n","train_dataset = ImageFolder(root = train_data_path, transform = train_transform)\n","test_dataset = ImageFolder(root = test_data_path, transform = test_transform)"],"metadata":{"id":"H8NWOUeKsEQL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","\n","from torch.utils.data import DataLoader\n","train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n","test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"],"metadata":{"id":"gija159CsEHb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]"],"metadata":{"id":"HTNnMVAGwhkq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_dataset)"],"metadata":{"id":"RIJxmlljwufU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader.dataset.class_to_idx"],"metadata":{"id":"g4T6qn6y_K3E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import random\n","\n","plt.figure(figsize = (10, 10))\n","\n","\n","inv_norm = transforms.Normalize(\n","    mean=[-m/s for m, s in zip(mean, std)],\n","    std=[1/s for s in std]\n",")\n","\n","\n","for i in range(16):\n","  plt.subplot(4, 4, i+1)\n","  idx = random.randint(0, len(train_dataset)-1)\n","  img, label = train_dataset[idx]\n","  plt.imshow(inv_norm(img).permute(1, 2, 0))\n","  if label == 0:\n","    t = 'cat'\n","  else:\n","    t = 'dog'\n","  plt.title(t)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"8tWhuXHosEFA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AlexNet(nn.Module):\n","  def __init__(self):\n","    super(AlexNet, self).__init__()\n","    self.relu = nn.ReLU()\n","    self.drop = nn.Dropout(0.5)\n","\n","    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 96, kernel_size = 11, stride = 4) # (227-11)/4+1 = 55\n","    self.pool1 = nn.MaxPool2d(kernel_size = 3, stride = 2) # (55-3)/2+1 = 27\n","\n","    self.conv2 = nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size = 5, padding = 2) # (27+2*2-5)/1+1 = 27\n","    self.pool2 = nn.MaxPool2d(kernel_size = 3, stride = 2) # (27-3)/2+1 = 13\n","\n","    self.conv3 = nn.Conv2d(in_channels = 256, out_channels = 384, kernel_size = 3, padding = 1, stride = 1) # (13+2*1-3)/1+1 = 13\n","    self.conv4 = nn.Conv2d(in_channels = 384, out_channels = 384, kernel_size = 3, padding = 1, stride = 1) # (13+2*1-3)/1+1 = 13\n","    self.conv5 = nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size = 3, padding = 1, stride = 1) # (13+2*1-3)/1+1 = 13\n","    self.pool3 = nn.MaxPool2d(kernel_size = 3, stride = 2) # (13-3)/2 + 1 = 6\n","\n","    self.fc1 = nn.Linear(256*6*6, 4096)\n","    self.fc2 = nn.Linear(4096, 4096)\n","    self.fc3 = nn.Linear(4096, 1000)\n","    self.fc4 = nn.Linear(1000, 256)\n","    self.fc5 = nn.Linear(256, 2)\n","\n","  def forward(self, x):\n","    out = self.conv1(x)\n","    out = self.relu(out)\n","    out = self.pool1(out)\n","\n","    out = self.conv2(out)\n","    out = self.relu(out)\n","    out = self.pool2(out)\n","\n","    out = self.conv3(out)\n","    out = self.relu(out)\n","    out = self.conv4(out)\n","    out = self.relu(out)\n","    out = self.conv5(out)\n","    out = self.relu(out)\n","    out = self.pool3(out)\n","\n","    out = self.fc1(out.view(-1, 256*6*6))\n","    out = self.relu(out)\n","    out = self.drop(out)\n","\n","    out = self.fc2(out)\n","    out = self.relu(out)\n","    out = self.drop(out)\n","\n","    out = self.fc3(out)\n","    out = self.relu(out)\n","\n","    out = self.fc4(out)\n","    out = self.relu(out)\n","\n","    out = self.fc5(out)\n","\n","    return out"],"metadata":{"id":"N1y-sodvltlc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AlexNet()\n","model.to(device)\n","print(model)"],"metadata":{"id":"kYQjfMRSna3X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","  print(name, param)"],"metadata":{"collapsed":true,"id":"6EJ3NkQzYNWR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn import CrossEntropyLoss\n","from torch.optim import Adam\n","\n","learning_rate = 0.05\n","criterion = CrossEntropyLoss()\n","optimizer = Adam(params = model.parameters(), lr = learning_rate)"],"metadata":{"id":"cVNq8ioBYT5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","\n","train_loss_list = []\n","train_acc_list = []\n","test_loss_list = []\n","test_acc_list = []\n","\n","test_acc = 0\n","\n","for epoch in range(epochs):\n","  model.train()\n","  train_loss = 0.0\n","  train_total = 0\n","  train_correct = 0.0\n","\n","  for img, label in train_loader:\n","    img, label = img.to(device), label.to(device)\n","    out = model(img) # (bs, num_classes) 형태의 raw logits\n","\n","    # label.long(): (bs, ) 형태의 정답 클래스 인덱스\n","    loss = criterion(out, label.long())\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    bs = img.size(0)\n","\n","    train_loss += loss.item() * bs\n","\n","    pred = out.argmax(dim = 1) # 로짓 출력 중 가장 높은\n","    train_correct += (pred == label).sum().item()\n","\n","    train_total += bs\n","\n","  avg_train_loss = train_loss / train_total\n","  avg_train_acc = train_correct / train_total * 100\n","\n","  train_loss_list.append(avg_train_loss)\n","  train_acc_list.append(avg_train_acc)\n","\n","\n","  model.eval()\n","  test_loss = 0.0\n","  test_total = 0\n","  test_correct = 0.0\n","\n","  with torch.no_grad():\n","    for img, label in test_loader:\n","      img, label = img.to(device), label.to(device)\n","      out = model(img)\n","\n","      loss = criterion(out, label.long())\n","\n","      bs = img.size(0)\n","      test_loss += loss.item() * bs\n","\n","      pred = out.argmax(dim = 1)\n","\n","      test_correct += (pred == label).sum().item()\n","\n","      test_total += bs\n","\n","  avg_test_loss = test_loss / test_total\n","  avg_test_acc = test_correct / test_total * 100\n","\n","  test_loss_list.append(avg_test_loss)\n","  test_acc_list.append(avg_test_acc)\n","\n","  print(f\"epoch: {epoch} | train loss: {avg_train_loss} train acc: {avg_train_acc} | test_loss: {avg_test_loss} test_acc: {avg_test_acc}\")\n","\n","  if avg_test_acc > test_acc:\n","    test_acc = avg_test_acc\n","    torch.save(model, 'model.pth')"],"metadata":{"id":"AXPKmqfgYug6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.subplot(2, 2, 1)\n","plt.plot(train_loss_list)\n","plt.title('train loss')\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(train_acc_list)\n","plt.title('train acc')\n","\n","plt.subplot(2, 2, 3)\n","plt.plot(test_loss_list)\n","plt.title('test loss')\n","\n","plt.subplot(2, 2, 4)\n","plt.plot(test_acc_list)\n","plt.title('test acc')\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"f43iJpF_bctq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 마지막 배치의 img, pred 와 label 비교\n","# test 의 경우 shuffle = False 이므로 순서대로 나오므로 마지막 배치는 dog 만 있음\n","\n","plt.figure(figsize = (10, 10))\n","\n","for i in range(20):\n","  plt.subplot(4, 5, i+1)\n","\n","  plt.imshow(img[i].permute(1, 2, 0).cpu())\n","  if pred[i].cpu().item() == 0:\n","    t_pred = 'cat'\n","  else:\n","    t_pred = 'dog'\n","\n","  if label[i].cpu().item() == 0:\n","    t_real = 'cat'\n","  else:\n","    t_real = 'dog'\n","\n","  plt.title(t_pred + \"(real: \" + t_real + \")\")\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ZUqPTIT-7S4X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. VGGNet"],"metadata":{"id":"EhGL_XO6QVjc"}},{"cell_type":"markdown","source":["3. **VGGNet**\n","- torchvision.models.vgg16, vgg19 가 이미 있지만 구현해봄\n","- ✅ 모델 구조\n","  - vgg16\n","\n","    <img src = \"https://miro.medium.com/v2/resize:fit:1400/1*p0QokDZh2Dmct_l4aS97nQ.png\" width = 550 height = 350>\n","  - vgg19\n","\n","    <img src = \"https://www.researchgate.net/publication/314237915/figure/tbl1/AS:667100565745668@1536060577444/Details-on-the-VGG19-architecture-For-each-layer-number-of-filters-parameters-and.png\" width = 300 height = 350>\n","  \n","  <img src = \"https://media5.datahacker.rs/2018/11/vgg-ispravljeno-.png\" width = 300 height = 600>\n","\n","- ✅ advanced 구조 (vgg 16)\n","  - dog-cat 문제 위해 f4, f5 추가 및 softmax 층 제거\n","  - dropout 층은 동일하게 f1, f2 에만 추가\n","    - [C1] conv1: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 64, `padding` = 1\n","    - [C2] conv2: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 64, `padding` = 1\n","    - [S1] sub-sampling(= down sampling)\n","      - 공간 해상도 (H*W) 줄이기\n","      - maxpool2d: `kernel_size` = 2, `stride` = 2\n","  $$ out = \\lfloor \\frac{in + 2p - k}{s} \\rfloor + 1 $$\n","    - [C3] conv3: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 128, `padding` = 1\n","    - [C4] conv4: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 128, `padding` = 1\n","    - [S2] maxpool2d: (`kernel_size` = 2), `stride` = 2\n","    - [C5] conv5: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 256, `padding` = 1\n","    - [C6] conv6: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 256, `padding` = 1\n","    - [C7] conv7: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 256, `padding` = 1\n","    - [S3] maxpool2d: (`kernel_size` = 2), `stride` = 2\n","    - [C8] conv8: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C9] conv9: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C10] conv10: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [S4] maxpool2d: (`kernel_size` = 2), `stride` = 2\n","    - [C11] conv11: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C12] conv12: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C13] conv13: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [S5] maxpool2d: (`kernel_size` = 2), `stride` = 2\n","    - [F1] fc1: `Linear(25088, 4096)` # 25088 은 224 img size 이므로\n","    - [D1] dropout: `Dropout(0.5)`\n","    - [F2] fc2: `Linear(4096, 4096)`\n","    - [D2] dropout: `Dropout(0.5)`\n","    - [F3] fc3: `Linear(4096, 1000)`\n","    - [F4] fc4: `Linear(1000, 256)`\n","    - [F5] fc5: `Linear(256, 2)`\n","\n","- ✅ advanced 구조 (vgg 19)\n","  - dog-cat 문제 위해 f4, f5 추가 및 softmax 층 제거\n","  - dropout 층은 동일하게 f1, f2 에만 추가\n","    - [C1] conv1: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 64, `padding` = 1\n","    - [C2] conv2: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 64, `padding` = 1\n","    - [S1] sub-sampling(= down sampling)\n","      - 공간 해상도 (H*W) 줄이기\n","      - maxpool2d: `kernel_size` = 2, `stride` = 2\n","  $$ out = \\lfloor \\frac{in + 2p - k}{s} \\rfloor + 1 $$\n","    - [C3] conv3: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 128, `padding` = 1\n","    - [C4] conv4: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 128, `padding` = 1\n","    - [S2] maxpool2d: (`kernel_size` = 2), `stride` = 2\n","    - [C5] conv5: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 256, `padding` = 1\n","    - [C6] conv6: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 256, `padding` = 1\n","    - [C7] conv7: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 256, `padding` = 1\n","    - [C8] conv8: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 256, `padding` = 1\n","    - [S3] maxpool2d: (`kernel_size` = 2), `stride` = 2\n","    - [C9] conv9: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C10] conv10: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C11] conv11: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C12] conv12: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [S4] maxpool2d: (`kernel_size` = 2), `stride` = 2\n","    - [C13] conv13: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C14] conv14: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C15] conv15: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [C16] conv16: 3*3 (`kernel_size` = 3), `stride` = 1, `out_channels` = 512, `padding` = 1\n","    - [S5] maxpool2d: (`kernel_size` = 2), `stride` = 2\n","    - [F1] fc1: `Linear(25088, 4096)` # 25088 은 224 img size 이므로\n","    - [D1] dropout: `Dropout(0.5)`\n","    - [F2] fc2: `Linear(4096, 4096)`\n","    - [D2] dropout: `Dropout(0.5)`\n","    - [F3] fc3: `Linear(4096, 1000)`\n","    - [F4] fc4: `Linear(1000, 256)`\n","    - [F5] fc5: `Linear(256, 2)`\n","\n","- ☑️ Result\n","  - 데이터 수 부족해서 성능 안 좋은 것임 (한 클래스만 찍힘)"],"metadata":{"id":"14YFtUzvQeru"}},{"cell_type":"code","source":[],"metadata":{"id":"-SeoICQ0Qerv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. cuda device\n","2. data path, transforms.Compose([transforms.]), ImageFolder\n","- train, test 나누기 (os.listdir, train_test_split)\n","- train, test 폴더 생성 및 아래 각 클래스 폴더 생성 (label 이름 인식을 위해서)\n","- 기존 이미지들 이동하기\n","- test 의 경우 transform 랜덤 변환 X\n","- ✅ vgg16,19 의 경우 정규화 필수 (ImageTransform)\n","\t- `transforms.Normalize(mean = [], std = [])`\n","\t- `ToTensor()` 뒤에 적용\n","\t- **mean, std 구하기: 반드시 train 셋만 가지고 구해야함**\n","\t\t- path 이용해서\n","\t\t- imagenet 관행\n","\t\t\t- mean = [0.485, 0.456, 0.406]\n","\t\t\t- std = [0.229, 0.224, 0.225]\n","3. batch size 변수, dataloader\n","4. 이미지 시각화\n","\t- subplot, imshow, title, axis off, tight_layout, show\n","\t- Normalize 했을 경우 역정규화해서 imshow\n","5. 모델: VGG16, VGG19\n","\t- 모델 정의 (torchvision.models 에 있지만 ✅class 로 모델 만들기✅)\n","\t- 모델 device 에 올리기 및 출력해보기\n","\t- 파라미터 확인하기\n","6. lr, criterion, optimizer 정의\n","7. epochs 수 정하기\n","- epoch for 문\n","\t- train 순서\n","\t\t- model train 모드로\n","\t\t- loss, total, correct = 0\n","\t\t- loader for문\n","\t\t\t- img, label device 에 올리기\n","\t\t\t- model 에 넣기\n","\t\t\t- loss\n","\t\t\t- optimizer zero grad, 기울기 계산, 역전파 수행 (train 에서만)\n","\t\t\t- 현재의 배치 구하고 loss 누적\n","\t\t\t- pred 구하고 correct 구하기\n","\t\t\t- total 구하기\n","\t\t- avg loss, acc 계산\n","\t\t- plot 그리기 위해 list 에 저장\n","\t- test 순서\n","\t\t- model eval 모드로\n","\t\t- loss, total, correct = 0\n","\t\t- no grad()\n","\t\t\t- loader for 문\n","\t\t\t\t- 동일\n","\t\t- avg loss, acc 계산\n","\t\t- plot 그리기 위해 list 에 저장\n","\t- loss, acc 출력\n","\t- 모델 갱신되면 저장\n","8. train, test acc, loss plot\n","9. 실제, 예측 결과, 이미지 시각화 (마지막 배치에서 일부만) -> 오분류 이미지 확인\n","10. (feature map 시각화)\n","\n"],"metadata":{"id":"BN5p1WQ0Qerw"}},{"cell_type":"code","source":[],"metadata":{"id":"4zZD6S1GuM7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"bXyCRsfpb3qP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"AiUldvZab4Mk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_path = '/content/drive/MyDrive/딥러닝 파이토치 교과서/6.1_Image Classification/data/train/**/*.*'\n","\n","import os, numpy as np\n","from PIL import Image\n","from glob import glob\n","\n","paths = glob(train_data_path, recursive=True)\n","sum_c = np.zeros(3, dtype=np.float64)\n","sq_c  = np.zeros(3, dtype=np.float64)\n","count = 0\n","\n","for p in paths:\n","    img = Image.open(p).convert(\"RGB\")\n","    img = img.resize((224, 224))                # 모델 입력 크기에 맞춤(권장)\n","    arr = np.asarray(img, dtype=np.float32) / 255.0  # [H,W,3] in [0,1]\n","    sum_c += arr.reshape(-1, 3).sum(axis=0)\n","    sq_c  += (arr.reshape(-1, 3)**2).sum(axis=0)\n","    count += arr.shape[0] * arr.shape[1]\n","\n","mean = (sum_c / count).tolist()\n","std  = np.sqrt(sq_c / count - np.array(mean)**2).tolist()\n","print(\"mean =\", mean, \"\\nstd =\", std)"],"metadata":{"id":"ICCAnM8nv6fK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_path = '/content/drive/MyDrive/딥러닝 파이토치 교과서/6.1_Image Classification/data/train'\n","test_data_path = '/content/drive/MyDrive/딥러닝 파이토치 교과서/6.1_Image Classification/data/test'\n","\n","from torchvision import transforms\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize(224, 224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean = mean, std = std)\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize(224, 224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean = mean, std = std)\n","])\n","\n","from torchvision.datasets import ImageFolder\n","\n","train_dataset = ImageFolder(root = train_data_path, transform = train_transform)\n","test_dataset = ImageFolder(root = test_data_path, transform = test_transform)"],"metadata":{"id":"6IC5v5o-tc5u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","\n","from torch.utils.data import DataLoader\n","\n","train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size)\n","test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size)"],"metadata":{"id":"qmsHvI3EwNf0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import random\n","\n","plt.figure(figsize = (10, 10))\n","\n","inv_norm = transforms.Normalize(\n","    mean=[-m/s for m, s in zip(mean, std)],\n","    std=[1/s for s in std]\n",")\n","\n","for i in range(20):\n","  idx = random.randint(0, len(train_dataset)-1)\n","  plt.subplot(4, 5, i+1)\n","  img, label = train_dataset[idx]\n","  plt.imshow(inv_norm(img).permute(1, 2, 0))\n","\n","  if label == 0:\n","    t = 'cat'\n","  else:\n","    t = 'dog'\n","\n","  plt.title(t)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"nB-yNujxxalp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class vgg16(nn.Module):\n","  def __init__(self):\n","    super(vgg16, self).__init__()\n","    self.relu = nn.ReLU()\n","    self.drop = nn.Dropout(0.5)\n","\n","    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n","    self.conv2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n","    self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n","    self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n","    self.conv4 = nn.Conv2d(128, 128, 3, 1, 1)\n","    self.conv5 = nn.Conv2d(128, 256, 3, 1, 1)\n","    self.conv6_7 = nn.Conv2d(256, 256, 3, 1, 1)\n","    self.conv8 = nn.Conv2d(256, 512, 3, 1, 1)\n","    self.conv9_13 = nn.Conv2d(512, 512, 3, 1, 1) # 9, 10, 11, 12, 13 모두 동일 # img size 49\n","\n","    self.fc1 = nn.Linear(25088, 4096) # 25088 = 512*7*7\n","    self.fc2 = nn.Linear(4096, 4096)\n","    self.fc3 = nn.Linear(4096, 1000)\n","    self.fc4 = nn.Linear(1000, 256)\n","    self.fc5 = nn.Linear(256, 2)\n","\n","  def forward(self, x):\n","    out = self.conv1(x)\n","    out = self.relu(out)\n","    out = self.conv2(out)\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.conv3(out)\n","    out = self.relu(out)\n","    out = self.conv4(out)\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.conv5(out)\n","    out = self.relu(out)\n","    out = self.conv6_7(out)\n","    out = self.relu(out)\n","    out = self.conv6_7(out)\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.conv8(out)\n","    out = self.relu(out)\n","    out = self.conv9_13(out)\n","    out = self.relu(out)\n","    out = self.conv9_13(out)\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.conv9_13(out)\n","    out = self.relu(out)\n","    out = self.conv9_13(out)\n","    out = self.relu(out)\n","    out = self.conv9_13(out)\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.fc1(out.view(-1, 512*7*7))\n","    out = self.relu(out)\n","    out = self.drop(out)\n","\n","    out = self.fc2(out)\n","    out = self.relu(out)\n","    out = self.drop(out)\n","\n","    out = self.fc3(out)\n","    out = self.relu(out)\n","\n","    out = self.fc4(out)\n","    out = self.relu(out)\n","\n","    out = self.fc5(out)\n","\n","    return out"],"metadata":{"id":"mZBxVaSCQXiV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class vgg19(nn.Module):\n","  def __init__(self):\n","    super(vgg16, self).__init__()\n","    self.relu = nn.ReLU()\n","    self.drop = nn.Dropout(0.5)\n","\n","    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n","    self.conv2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n","    self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n","    self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n","    self.conv4 = nn.Conv2d(128, 128, 3, 1, 1)\n","    self.conv5 = nn.Conv2d(128, 256, 3, 1, 1)\n","    self.conv6_8 = nn.Conv2d(256, 256, 3, 1, 1)\n","    self.conv9 = nn.Conv2d(256, 512, 3, 1, 1)\n","    self.conv10_16 = nn.Conv2d(512, 512, 3, 1, 1) # 9, 10, 11, 12, 13 모두 동일 # img size 49\n","\n","    self.fc1 = nn.Linear(25088, 4096) # 25088 = 512*7*7\n","    self.fc2 = nn.Linear(4096, 4096)\n","    self.fc3 = nn.Linear(4096, 1000)\n","    self.fc4 = nn.Linear(1000, 256)\n","    self.fc5 = nn.Linear(256, 2)\n","\n","  def forward(self, x):\n","    out = self.conv1(x)\n","    out = self.relu(out)\n","    out = self.conv2(out)\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.conv3(out)\n","    out = self.relu(out)\n","    out = self.conv4(out)\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.conv5(out)\n","    out = self.relu(out)\n","    out = self.conv6_8(out)\n","    out = self.relu(out)\n","    out = self.conv6_8(out)\n","    out = self.relu(out)\n","    out = self.conv6_8(out)\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.conv9(out)\n","    out = self.relu(out)\n","    out = self.conv10_16(out) # 10\n","    out = self.relu(out)\n","    out = self.conv10_16(out) # 11\n","    out = self.relu(out)\n","    out = self.conv10_16(out) # 12\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.conv10_16(out) # 13\n","    out = self.relu(out)\n","    out = self.conv10_16(out) # 14\n","    out = self.relu(out)\n","    out = self.conv10_16(out) # 15\n","    out = self.relu(out)\n","    out = self.conv10_16(out) # 16\n","    out = self.relu(out)\n","    out = self.pool(out)\n","\n","    out = self.fc1(out.view(-1, 512*7*7))\n","    out = self.relu(out)\n","    out = self.drop(out)\n","\n","    out = self.fc2(out)\n","    out = self.relu(out)\n","    out = self.drop(out)\n","\n","    out = self.fc3(out)\n","    out = self.relu(out)\n","\n","    out = self.fc4(out)\n","    out = self.relu(out)\n","\n","    out = self.fc5(out)\n","\n","    return out"],"metadata":{"id":"Y9YD3ws_pl8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = vgg16()\n","model.to(device)\n","\n","print(model)"],"metadata":{"id":"EWX8TWzrs_3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","  print(name, param)"],"metadata":{"id":"Td4jlb-6zLhR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn import CrossEntropyLoss\n","from torch.optim import Adam\n","\n","learning_rate = 0.05\n","criterion = CrossEntropyLoss()\n","optimizer = Adam(params = model.parameters(), lr = learning_rate)"],"metadata":{"id":"d4I6ZzwlzMGx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","test_acc = 0.0\n","train_loss_list = []\n","train_acc_list = []\n","test_loss_list = []\n","test_acc_list = []\n","\n","for epoch in range(epochs):\n","  model.train()\n","  train_loss = 0.0\n","  train_total = 0\n","  train_correct = 0.0\n","\n","  for img, label in train_loader:\n","    img, label = img.to(device), label.to(device)\n","    out = model(img)\n","\n","    loss = criterion(out, label)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    bs = img.size(0)\n","\n","    train_loss += loss.item() * bs\n","\n","    pred = out.argmax(dim = 1)\n","\n","    train_correct += (out == label).sum().item()\n","\n","    train_total += bs\n","\n","  avg_train_loss = train_loss / train_total\n","  avg_train_acc = train_correct / train_total * 100\n","\n","  train_loss_list.append(avg_train_loss)\n","  train_acc_list.append(avg_train_acc)\n","\n","  model.eval()\n","\n","  test_loss = 0.0\n","  test_total = 0\n","  test_correct = 0.0\n","\n","  with torch.no_grad():\n","    for img, label in test_loader:\n","      img, label = img.to(device), label.to(device)\n","\n","      out = model(img)\n","\n","      loss = criterion(out, label)\n","\n","      bs = img.size(0)\n","      test_loss += loss.item() * bs\n","\n","      pred = out.argmax(dim = 1)\n","      test_correct += (pred == label).sum().item()\n","\n","      test_total += bs\n","\n","  avg_test_loss = test_loss / test_total\n","  avg_test_acc = test_correct / test_total * 100\n","\n","  test_loss_list.append(avg_test_loss)\n","  test_acc_list.append(avg_test_acc)\n","\n","  print(f\"epoch: {epoch} | train loss: {avg_train_loss}, train acc: {avg_train_acc} | test loss: {avg_test_loss}, test acc: {avg_test_acc}\")\n","\n","  if avg_test_acc > test_acc:\n","    test_acc = avg_test_acc\n","    torch.save(model, 'model.pth')"],"metadata":{"id":"m2R3UYggzogD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.subplot(2, 2, 1)\n","plt.plot(train_loss_list)\n","plt.title('train loss')\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(train_acc_list)\n","plt.title('train loss')\n","\n","plt.subplot(2, 2, 3)\n","plt.plot(test_loss_list)\n","plt.title('test loss')\n","\n","plt.subplot(2, 2, 4)\n","plt.plot(test_acc_list)\n","plt.title('test acc')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"LgghG5pv3tLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 마지막 배치의 img, pred 와 label 비교\n","# test 의 경우 shuffle = False 이므로 순서대로 나오므로 마지막 배치는 dog 만 있음\n","\n","plt.figure(figsize = (10, 10))\n","\n","for i in range(20):\n","  plt.subplot(4, 5, i+1)\n","\n","  plt.imshow(img[i].permute(1, 2, 0).cpu())\n","  if pred[i].cpu().item() == 0:\n","    t_pred = 'cat'\n","  else:\n","    t_pred = 'dog'\n","\n","  if label[i].cpu().item() == 0:\n","    t_real = 'cat'\n","  else:\n","    t_real = 'dog'\n","\n","  plt.title(t_pred + \"(real: \" + t_real + \")\")\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ksRtoebG3-nV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. ResNet"],"metadata":{"id":"75lZi4Gz7suH"}},{"cell_type":"markdown","source":["4. **ResNet**\n","- torchvision.models.resnet18 등이 이미 있지만 구현해봄\n","- ✅ 모델 구조\n","  - resnet\n","\n","    <img src = \"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FbUhp2u%2Fbtq22b5u0gX%2FAAAAAAAAAAAAAAAAAAAAAOepXy_jO_vYOnZ6DHgHOsCkknS_ZydHU1IK1rs3ruwg%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1756652399%26allow_ip%3D%26allow_referer%3D%26signature%3DsNZfxmKm5DHIu4vLsdCnLzEBQsw%253D\" width = 450 height = 250>\n","\n","- ✅ advanced 구조 (resnet 18)\n","  - 마지막 fc 의 num_classes 만 변경\n","    - [C1] conv1: 7*7 (`kernel_size` = 7), `stride` = 2, `out_channels` = 64, `padding` = 3\n","    - [B1] BN: BatchNorm2d(64)\n","    - relu\n","    - [S1] maxpool2d: (`kernel_size` = 3, `stride` = 2, `padding` = 1)\n","\n","    - Layer1\n","      - Basic Block\n","        - [C2] conv2: 3*3, `stride` = 1, `in_channels` = 64, `out_channels` = 64, `padding` = 1\n","        - [B2] BN(64)\n","        - relu\n","        - [C3] conv3: 3*3, `stride` = 1, `in_channels` = 64, `out_channels` = 64, `padding` = 1\n","        - [B3] BN(64)\n","        - skip connection (identity)\n","        - relu\n","\n","    - Layer2\n","      - Basic Block1\n","        - [C4] conv4: 3*3, `stride` = 2, `in_channels` = 64, `out_channels` = 128, `padding` = 1\n","        - [B4] BN(128)\n","        - relu\n","        - [C5] conv5: 3*3, `stride` = 1, `in_channels` = 128, `out_channels` = 128, `padding` = 1\n","        - [B5] BN(128)\n","        - skip connection (downsample: 1*1 conv, stride=2, out=128 + BN)\n","        - relu\n","      - Basic Block2\n","        - [C6] conv6: 3*3, `stride` = 1, `in_channels` = 128, `out_channels` = 128, `padding` = 1\n","        - [B6] BN(128)\n","        - relu\n","        - [C7] conv7: 3*3, `stride` = 1, `in_channels` = 128, `out_channels` = 128, `padding` = 1\n","        - [B7] BN(128)\n","        - skip connection (identity)\n","        - relu\n","\n","    - Layer3\n","      - Basic Block1\n","        - [C8] conv8: 3*3, `stride` = 2, `in_channels` = 128, `out_channels` = 256, `padding` = 1\n","        - [B8] BN(256)\n","        - relu\n","        - [C9] conv9: 3*3, `stride` = 1, `in_channels` = 256, `out_channels` = 256, `padding` = 1\n","        - [B9] BN(256)\n","        - skip connection (downsample: 1*1 conv, stride=2, out=256 + BN)\n","        - relu\n","      - Basic Block2\n","        - [C10] conv10: 3*3, `stride` = 1, `in_channels` = 256, `out_channels` = 256, `padding` = 1\n","        - [B10] BN(256)\n","        - relu\n","        - [C11] conv11: 3*3, `stride` = 1, `in_channels` = 256, `out_channels` = 256, `padding` = 1\n","        - [B11] BN(256)\n","        - skip connection (identity)\n","        - relu\n","\n","    - Layer4\n","      - Basic Block1\n","        - [C12] conv12: 3*3, `stride` = 2, `in_channels` = 256, `out_channels` = 512, `padding` = 1\n","        - [B12] BN(512)\n","        - relu\n","        - [C13] conv13: 3*3, `stride` = 1, `in_channels` = 512, `out_channels` = 512, `padding` = 1\n","        - [B13] BN(512)\n","        - skip connection (downsample: 1*1 conv, stride=2, out=512 + BN)\n","        - relu\n","      - Basic Block2\n","        - [C14] conv14: 3*3, `stride` = 1, `in_channels` = 512, `out_channels` = 512, `padding` = 1\n","        - [B14] BN(512)\n","        - relu\n","        - [C15] conv15: 3*3, `stride` = 1, `in_channels` = 512, `out_channels` = 512, `padding` = 1\n","        - [B15] BN(512)\n","        - skip connection (identity)\n","        - relu\n","\n","    - [G1] AdaptiveAvgPool2d((1,1))\n","    - [F] fc: Linear(512, 2)\n","\n","\n","- ☑️ Result\n","  - 데이터 수 부족해서 성능 안 좋은 것임 (한 클래스만 찍힘)"],"metadata":{"id":"LzyeVPlB7suI"}},{"cell_type":"code","source":[],"metadata":{"id":"ztdZzHiX7suI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. cuda device\n","2. data path, transforms.Compose([transforms.]), ImageFolder\n","- train, test 나누기 (os.listdir, train_test_split)\n","- train, test 폴더 생성 및 아래 각 클래스 폴더 생성 (label 이름 인식을 위해서)\n","- 기존 이미지들 이동하기\n","- test 의 경우 transform 랜덤 변환 X\n","- ✅ resnet 의 경우 정규화 필수 (ImageTransform)\n","\t- `transforms.Normalize(mean = [], std = [])`\n","\t- `ToTensor()` 뒤에 적용\n","\t- **mean, std 구하기: 반드시 train 셋만 가지고 구해야함**\n","\t\t- path 이용해서\n","\t\t- imagenet 관행\n","\t\t\t- mean = [0.485, 0.456, 0.406]\n","\t\t\t- std = [0.229, 0.224, 0.225]\n","3. batch size 변수, dataloader\n","4. 이미지 시각화\n","\t- subplot, imshow, title, axis off, tight_layout, show\n","\t- Normalize 했을 경우 역정규화해서 imshow\n","5. 모델: ResNet\n","\t- 모델 정의 (torchvision.models 에 있지만 ✅class 로 모델 만들기✅)\n","\t- 모델 device 에 올리기 및 출력해보기\n","\t- 파라미터 확인하기\n","6. lr, criterion, optimizer 정의\n","7. epochs 수 정하기\n","- epoch for 문\n","\t- train 순서\n","\t\t- model train 모드로\n","\t\t- loss, total, correct = 0\n","\t\t- loader for문\n","\t\t\t- img, label device 에 올리기\n","\t\t\t- model 에 넣기\n","\t\t\t- loss\n","\t\t\t- optimizer zero grad, 기울기 계산, 역전파 수행 (train 에서만)\n","\t\t\t- 현재의 배치 구하고 loss 누적\n","\t\t\t- pred 구하고 correct 구하기\n","\t\t\t- total 구하기\n","\t\t- avg loss, acc 계산\n","\t\t- plot 그리기 위해 list 에 저장\n","\t- test 순서\n","\t\t- model eval 모드로\n","\t\t- loss, total, correct = 0\n","\t\t- no grad()\n","\t\t\t- loader for 문\n","\t\t\t\t- 동일\n","\t\t- avg loss, acc 계산\n","\t\t- plot 그리기 위해 list 에 저장\n","\t- loss, acc 출력\n","\t- 모델 갱신되면 저장\n","8. train, test acc, loss plot\n","9. 실제, 예측 결과, 이미지 시각화 (마지막 배치에서 일부만) -> 오분류 이미지 확인\n","10. (feature map 시각화)\n","\n"],"metadata":{"id":"v7gfq0h67suI"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"QC7t8P0qA6h9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","device = torch.cuda.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"8xKN-64Bcztm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean =\n","std ="],"metadata":{"id":"3h014wvzesh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_path = ''\n","test_data_path = ''\n","\n","from torchvision import transforms\n","train_transform = transforms.Compose([\n","    transforms.Resize([224, 224]),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean = mean, std = std)\n","])\n","test_transform = transforms.Compose([\n","    transforms.Resize([224, 224]),\n","    transforms.ToTensor()\n","])\n","\n","from torchvision.datasets import ImageFolder\n","train_dataset = ImageFolder(train_data_path, train_transform)\n","test_dataset = ImageFolder(test_data_path, test_transform)"],"metadata":{"id":"D1d4IYdPczpX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","\n","from torch.utils.data import DataLoader\n","\n","train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n","test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"],"metadata":{"id":"nuCyklakfafN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import random\n","\n","plt.figure(figsize = (10, 10))\n","\n","\n","inv_norm = transforms.Normalize(\n","    mean=[-m/s for m, s in zip(mean, std)],\n","    std=[1/s for s in std]\n",")\n","\n","for i in range(16):\n","  plt.subplot(4, 4, i+1)\n","  idx = random.randint(0, len(train_dataset)-1)\n","  img, label = train_dataset[idx]\n","  plt.imshow(inv_norm(img).permute(1, 2, 0))\n","\n","  if label == 0:\n","    t = 'cat'\n","  else:\n","    t = 'dog'\n","  plt.title(t)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"aipa6xDafaUI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class basicblock(nn.Module):\n","  def __init__(self, in_ch, out_ch, stride=1, down = None):\n","    super(basicblock, self).__init__()\n","\n","    self.down = down\n","    self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride, 1)\n","    self.b1 = nn.BatchNorm2d(out_ch)\n","    self.relu = nn.ReLU()\n","\n","    self.conv2 = nn.Conv2d(out_ch, out_ch, 3, 1, 1)\n","    self.b2 = nn.BatchNorm2d(out_ch)\n","\n","    self.conv3 = nn.Conv2d(in_ch, out_ch, 1, 2, 0)\n","    self.b3 = nn.BatchNorm2d(out_ch)\n","\n","  def forward(self, x):\n","    out = self.conv1(x)\n","    out = self.b1(out)\n","    out = self.relu(out)\n","    out = self.conv2(out)\n","    out_main = self.b2(out)\n","\n","    # down sample\n","    if self.down == True:\n","      out = self.conv3(x)\n","      identity = self.b3(out)\n","      out = out_main + identity\n","      out = self.relu(out)\n","      return out\n","    else:\n","      return self.relu(out_main + x)\n","\n","\n","class resnet18(nn.Module):\n","  def __init__(self):\n","    super(resnet18, self).__init__()\n","    self.relu = ReLU()\n","\n","    self.conv1 = Conv2d(in_channels = 3, out_channels = 64, kernel_size = 7, stride = 2, padding = 3)\n","    self.b1 = BatchNorm2d(64)\n","    self.pool1 = MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","\n","    self.bb = basicblock(64, 64, 1, False)\n","    self.layer1 = nn.Sequential(self.bb)\n","\n","    self.bb1 = basicblock(64, 128, 2, True)\n","    self.bb2 = basicblock(128, 128, 1, False)\n","    self.layer2 = nn.Sequential(self.bb1, self.bb2)\n","\n","    self.bb1 = basicblock(128, 256, 2, True)\n","    self.bb2 = basicblock(256, 256, 1, False)\n","    self.layer3 = nn.Sequential(self.bb1, self.bb2)\n","\n","    self.bb1 = basicblock(256, 512, 2, True)\n","    self.bb2 = basicblock(512, 512, 1, False)\n","    self.layer4 = nn.Sequential(self.bb1, self.bb2)\n","\n","    self.pool2 = nn.AdaptiveAvgPool2d(1)\n","    self.fc = Linear(512, 2)\n","\n","  def skip(self, x, out):\n","    return x + out\n","\n","  def forward(self, x):\n","    out = self.conv1(x)\n","    out = self.b1(out)\n","    out = self.relu(out)\n","    out = self.pool1(out)\n","\n","    # [layer1]\n","    out = self.layer1(out)\n","\n","    # [layer2]\n","    out = self.layer2(out)\n","\n","    # [layer3]\n","    out = self.layer3(out)\n","\n","    # [layer4]\n","    out = self.layer4(out)\n","\n","    out = self.pool2(out)\n","    out = self.fc(out.view(-1, 512))\n","\n","    return out\n"],"metadata":{"id":"E06WBodHA6ay"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = resnet18()\n","model.to(device)\n","\n","print(model)"],"metadata":{"id":"j6Ly6FEthaGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","  print(name, param)"],"metadata":{"id":"YQSLMEkEhf3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","from torch.optim import Adam\n","\n","learning_rate = 0.01\n","criterion = nn.CrossEntropyLoss()\n","optimizer = Adam(params = model.parameters(), lr = learning_rate)"],"metadata":{"id":"MFxIzzPAhl6C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","\n","train_loss_list = []\n","train_acc_list = []\n","\n","test_loss_list = []\n","test_acc_list = []\n","\n","test_acc = 0.0\n","\n","for epoch in range(epochs):\n","  model.train()\n","  train_loss = 0.0\n","  train_total = 0\n","  train_correct = 0.0\n","\n","  for img, label in train_loader:\n","    img, label = img.to(device), label.to(device)\n","    out = model(img)\n","\n","    loss = criterion(out, label)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    bs = img.size(0)\n","\n","    train_loss += loss.item() * bs\n","\n","    pred = out.argmax(dim = 1)\n","    train_correct += (pred == label).sum().item()\n","\n","    train_total += bs\n","\n","  avg_train_loss = train_loss / train_total\n","  avg_train_acc = train_correct / train_total * 100\n","\n","  train_loss_list.append(avg_train_loss)\n","  train_acc_list.append(avg_train_acc)\n","\n","\n","  model.eval()\n","  test_loss = 0.0\n","  test_total = 0\n","  test_correct = 0.0\n","\n","  with torch.no_grad():\n","    for img, label in test_loader:\n","      img, label = img.to(device), label.to(device)\n","      out = model(img)\n","\n","      loss = criterion(out, label)\n","\n","      bs = img.size(0)\n","\n","      test_loss += loss.item() * bs\n","\n","      pred = out.argmax(dim = 1)\n","      test_correct += (pred == label).sum().item()\n","\n","      test_total += bs\n","\n","  avg_test_loss = test_loss / test_total\n","  avg_test_acc = test_correct / test_total * 100\n","\n","  test_loss_list.append(avg_test_loss)\n","  test_acc_list.append(avg_test_acc)\n","\n","  print(f\"epoch:{epoch} | train loss: {avg_train_loss} train acc: {avg_train_acc} | test loss: {avg_test_loss} test acc: {avg_test_acc}\")\n","\n","\n","  if avg_test_acc > test_acc:\n","    test_acc = avg_test_acc\n","    torch.save(model, 'model.pth')"],"metadata":{"id":"pp8tLId4iQpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.subplot(2, 2, 1)\n","plt.plot(train_loss_list)\n","plt.title('train loss')\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(train_acc_list)\n","plt.title('train acc')\n","\n","plt.subplot(2, 2, 3)\n","plt.plot(test_loss_list)\n","plt.title('test loss')\n","\n","plt.subplot(2, 2, 4)\n","plt.plot(test_acc_list)\n","plt.title('test acc')\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"xIDdo3KXlOTT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 마지막 배치의 img, pred 와 label 비교\n","# test 의 경우 shuffle = False 이므로 순서대로 나오므로 마지막 배치는 dog 만 있음\n","\n","plt.figure(figsize = (10, 10))\n","\n","for i in range(20):\n","  plt.subplot(4, 5, i+1)\n","\n","  plt.imshow(img[i].permute(1, 2, 0).cpu())\n","  if pred[i].cpu().item() == 0:\n","    t_pred = 'cat'\n","  else:\n","    t_pred = 'dog'\n","\n","  if label[i].cpu().item() == 0:\n","    t_real = 'cat'\n","  else:\n","    t_real = 'dog'\n","\n","  plt.title(t_pred + \"(real: \" + t_real + \")\")\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"sZrYaslvlj6J"},"execution_count":null,"outputs":[]}]}